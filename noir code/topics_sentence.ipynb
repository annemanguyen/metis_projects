{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop = stop + [u'said',u'went',u'could',u'would',u'got',u'get',u'looked',u'around',u'man',u'one',u'put',u'back',\\\n",
    "               u'like',u'know',u'little',u\"n't\",u\"r'e\", u\"'ll\", u\"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "path = '/home/amn34/metis/stuff/noirs/chandler/'\n",
    "for books in glob.glob(os.path.join(path, '*.txt')):\n",
    "    doc = open(books).read()\n",
    "    doc = doc.lower()\n",
    "    doc = doc.decode('ascii','ignore')\n",
    "    \n",
    "    docsentences = sent_tokenize(doc)\n",
    "    \n",
    "    sentencelist = [[i] for i in docsentences]\n",
    "    \n",
    "    for i in sentencelist:\n",
    "        sentencewords = word_tokenize(i[0])\n",
    "        stopped = [w for w in sentencewords if (not w in stop) & (len(w) > 2)]\n",
    "        texts.append(stopped)\n",
    "    #p_stem = PorterStemmer()\n",
    "    #stemmed_words = [p_stem.stem(i) for i in stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [i for i in texts if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in texts: print 'book:', i[0:50], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, alpha = 'auto', eta='auto', id2word = dictionary, passes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u\"0.020*think + 0.019*something + 0.015*gun + 0.015*look + 0.015*marlowe + 0.015*'ll + 0.014*might + 0.013*take + 0.013*took + 0.013*told + 0.012*going + 0.011*gave + 0.010*mr. + 0.010*another + 0.009*away + 0.009*business + 0.009*somebody + 0.009*call + 0.008*sure + 0.008*far\"),\n",
       " (1,\n",
       "  u\"0.110*n't + 0.017*time + 0.015*'re + 0.012*see + 0.012*voice + 0.011*want + 0.011*anything + 0.011*asked + 0.011*let + 0.010*long + 0.009*much + 0.009*say + 0.009*tell + 0.009*come + 0.008*nice + 0.008*even + 0.008*kind + 0.008*guy + 0.008*make + 0.007*head\"),\n",
       " (2,\n",
       "  u'0.014*door + 0.013*eyes + 0.009*came + 0.009*still + 0.007*stood + 0.007*open + 0.006*looking + 0.006*mouth + 0.006*light + 0.006*house + 0.006*face + 0.006*white + 0.006*made + 0.005*two + 0.005*cigarette + 0.005*opened + 0.005*hands + 0.005*night + 0.005*police + 0.005*last'),\n",
       " (3,\n",
       "  u\"0.028*way + 0.025*nothing + 0.019*good + 0.016*'ve + 0.015*money + 0.015*lot + 0.015*thought + 0.014*steelgrave + 0.013*dead + 0.012*started + 0.011*thing + 0.011*talk + 0.010*always + 0.010*seemed + 0.010*heard + 0.010*work + 0.009*guess + 0.009*must + 0.008*quite + 0.008*found\"),\n",
       " (4,\n",
       "  u'0.017*right + 0.017*desk + 0.015*room + 0.014*hand + 0.012*turned + 0.010*across + 0.010*well + 0.010*sat + 0.010*french + 0.010*slowly + 0.010*side + 0.009*car + 0.009*knew + 0.009*behind + 0.009*chair + 0.009*left + 0.008*along + 0.007*leaned + 0.007*reached + 0.007*stopped')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel3 = gensim.models.ldamodel.LdaModel(corpus_tfidf, num_topics=7, alpha = 'auto', id2word = dictionary, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.013*really + 0.012*amigo + 0.010*night + 0.010*dr. + 0.009*please + 0.009*moment + 0.009*closed + 0.007*lagardie + 0.007*may + 0.007*fingers + 0.007*saw + 0.006*minute + 0.006*makes + 0.005*perhaps + 0.005*sit + 0.005*hurt + 0.005*mrs. + 0.005*stop + 0.005*apartment + 0.005*years'),\n",
       " (1,\n",
       "  u'0.027*nothing + 0.024*marlowe + 0.018*come + 0.018*well + 0.014*never + 0.013*business + 0.012*nodded + 0.011*mean + 0.011*thing + 0.011*talk + 0.011*mr. + 0.011*guess + 0.010*weld + 0.010*drink + 0.008*mavis + 0.007*day + 0.007*care + 0.007*rather + 0.006*believe + 0.006*picture'),\n",
       " (2,\n",
       "  u'0.018*good + 0.015*maybe + 0.014*give + 0.013*stared + 0.012*ever + 0.011*heard + 0.011*keep + 0.010*course + 0.008*sorry + 0.007*point + 0.007*laughed + 0.007*sort + 0.006*pretty + 0.006*wade + 0.005*suddenly + 0.005*shrugged + 0.005*cards + 0.005*cleveland + 0.005*safe + 0.005*touch'),\n",
       " (3,\n",
       "  u'0.029*asked + 0.016*yes + 0.015*steelgrave + 0.014*name + 0.012*call + 0.011*orrin + 0.010*answer + 0.009*ought + 0.008*quest + 0.008*hung + 0.008*city + 0.008*called + 0.007*shook + 0.007*suppose + 0.007*wanted + 0.007*doctor + 0.006*seen + 0.006*bay + 0.006*mind + 0.006*friend'),\n",
       " (4,\n",
       "  u\"0.051*n't + 0.011*time + 0.010*think + 0.010*'re + 0.010*eyes + 0.010*want + 0.010*way + 0.009*something + 0.008*let + 0.008*came + 0.008*tell + 0.008*room + 0.008*look + 0.008*long + 0.008*voice + 0.007*face + 0.007*still + 0.007*took + 0.007*head + 0.006*make\"),\n",
       " (5,\n",
       "  u\"0.016*see + 0.016*anything + 0.014*say + 0.014*'ll + 0.014*away + 0.013*much + 0.013*gun + 0.013*french + 0.013*turned + 0.013*told + 0.011*take + 0.011*money + 0.011*might + 0.010*house + 0.009*started + 0.009*car + 0.008*dead + 0.008*beifus + 0.008*far + 0.007*better\"),\n",
       " (6,\n",
       "  u'0.020*right + 0.017*door + 0.013*desk + 0.012*hand + 0.012*thought + 0.011*stood + 0.010*sat + 0.008*open + 0.008*chair + 0.008*mouth + 0.007*leaned + 0.007*phone + 0.007*reached + 0.007*killed + 0.007*softly + 0.007*cigarette + 0.007*smile + 0.007*yeah + 0.007*hands + 0.007*glass')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel3.print_topics(num_topics=7, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus,id2word=dictionary,num_topics=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.983*\"n\\'t\" + 0.060*\"anything\" + 0.048*\"think\" + 0.045*\"want\" + 0.037*\"say\" + 0.035*\"see\" + 0.031*\"even\" + 0.031*\"tell\" + 0.029*\"much\" + 0.029*\"time\" + 0.027*\"make\" + 0.025*\"look\" + 0.024*\"way\" + 0.019*\"well\" + 0.019*\"enough\" + 0.019*\"something\" + 0.018*\"come\" + 0.018*\"take\" + 0.017*\"let\" + 0.017*\"long\"'),\n",
       " (1,\n",
       "  u'0.606*\"door\" + 0.171*\"came\" + 0.162*\"eyes\" + 0.162*\"room\" + 0.144*\"open\" + 0.144*\"face\" + 0.138*\"hand\" + 0.135*\"opened\" + 0.130*\"time\" + 0.120*\"front\" + 0.112*\"desk\" + 0.110*\"car\" + 0.106*\"long\" + 0.105*\"two\" + 0.104*\"across\" + 0.102*\"away\" + 0.100*\"head\" + 0.097*\"right\" + 0.094*\"behind\" + 0.089*\"stood\"'),\n",
       " (2,\n",
       "  u'-0.654*\"door\" + 0.365*\"time\" + 0.202*\"eyes\" + 0.169*\"long\" + 0.166*\"face\" + 0.142*\"right\" + 0.115*\"way\" + 0.112*\"hand\" + 0.110*\"\\'re\" + -0.107*\"opened\" + 0.098*\"something\" + -0.097*\"open\" + 0.097*\"head\" + 0.091*\"think\" + 0.087*\"away\" + 0.084*\"\\'ll\" + -0.080*\"n\\'t\" + 0.078*\"see\" + 0.077*\"might\" + 0.075*\"took\"'),\n",
       " (3,\n",
       "  u'-0.728*\"time\" + 0.413*\"eyes\" + 0.233*\"face\" + -0.196*\"door\" + -0.188*\"long\" + 0.159*\"hand\" + -0.095*\"think\" + 0.093*\"head\" + -0.081*\"\\'re\" + 0.076*\"still\" + -0.073*\"\\'ll\" + 0.070*\"desk\" + 0.062*\"white\" + 0.060*\"turned\" + 0.060*\"right\" + 0.058*\"look\" + 0.055*\"black\" + 0.052*\"slowly\" + 0.051*\"dark\" + 0.051*\"sat\"'),\n",
       " (4,\n",
       "  u'0.570*\"eyes\" + 0.411*\"time\" + -0.262*\"\\'re\" + -0.248*\"right\" + 0.212*\"face\" + -0.194*\"think\" + -0.194*\"way\" + -0.140*\"\\'ll\" + 0.134*\"long\" + -0.116*\"car\" + -0.107*\"hand\" + -0.095*\"away\" + -0.095*\"marlowe\" + -0.090*\"might\" + -0.089*\"gun\" + -0.087*\"see\" + -0.073*\"mr.\" + -0.072*\"want\" + -0.071*\"two\" + -0.071*\"guy\"'),\n",
       " (5,\n",
       "  u'0.393*\"\\'re\" + 0.367*\"eyes\" + 0.346*\"think\" + -0.313*\"hand\" + -0.223*\"right\" + 0.168*\"something\" + 0.167*\"\\'ll\" + -0.153*\"gun\" + -0.151*\"time\" + -0.147*\"took\" + 0.139*\"marlowe\" + 0.134*\"see\" + -0.124*\"away\" + 0.120*\"door\" + -0.119*\"came\" + -0.119*\"desk\" + 0.111*\"way\" + 0.106*\"mr.\" + 0.104*\"might\" + -0.101*\"car\"'),\n",
       " (6,\n",
       "  u'-0.576*\"right\" + -0.349*\"hand\" + 0.330*\"way\" + -0.280*\"\\'re\" + 0.210*\"room\" + 0.189*\"car\" + 0.172*\"two\" + 0.170*\"came\" + -0.147*\"think\" + -0.146*\"gun\" + -0.146*\"eyes\" + -0.137*\"door\" + -0.109*\"time\" + 0.097*\"across\" + 0.086*\"see\" + 0.083*\"house\" + 0.076*\"long\" + 0.070*\"desk\" + -0.060*\"took\" + 0.054*\"sat\"'),\n",
       " (7,\n",
       "  u'-0.699*\"way\" + 0.338*\"face\" + -0.278*\"eyes\" + -0.255*\"right\" + 0.207*\"think\" + 0.202*\"came\" + 0.202*\"\\'re\" + -0.113*\"hand\" + -0.094*\"long\" + 0.084*\"two\" + -0.082*\"gun\" + 0.082*\"desk\" + 0.074*\"marlowe\" + 0.066*\"mr.\" + 0.065*\"away\" + -0.063*\"want\" + -0.061*\"\\'ll\" + -0.058*\"door\" + 0.055*\"much\" + -0.055*\"come\"'),\n",
       " (8,\n",
       "  u'0.644*\"see\" + -0.379*\"think\" + -0.300*\"way\" + 0.290*\"want\" + 0.238*\"\\'ll\" + -0.223*\"\\'re\" + 0.135*\"mr.\" + 0.128*\"something\" + 0.127*\"marlowe\" + 0.102*\"right\" + -0.101*\"room\" + 0.099*\"came\" + 0.088*\"let\" + 0.084*\"look\" + 0.082*\"voice\" + -0.082*\"long\" + -0.080*\"desk\" + -0.057*\"across\" + -0.047*\"sat\" + 0.040*\"tell\"'),\n",
       " (9,\n",
       "  u'0.786*\"face\" + 0.332*\"way\" + -0.320*\"eyes\" + -0.186*\"room\" + -0.167*\"two\" + -0.122*\"came\" + -0.121*\"car\" + -0.084*\"think\" + 0.084*\"door\" + -0.059*\"\\'re\" + -0.049*\"much\" + -0.048*\"house\" + -0.046*\"desk\" + 0.045*\"want\" + 0.044*\"see\" + -0.044*\"big\" + 0.039*\"let\" + -0.035*\"made\" + -0.035*\"front\" + -0.034*\"along\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=100, stop_words=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentencetexts = []\n",
    "path = '/home/amn34/metis/stuff/noirs/chandler/'\n",
    "for books in glob.glob(os.path.join(path, '*.txt')):\n",
    "    doc = open(books).read()\n",
    "    doc = doc.lower()\n",
    "    doc = doc.decode('ascii','ignore')\n",
    "    \n",
    "    sentencetexts.extend(sent_tokenize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidfnmf = tfidf_vectorizer.fit_transform(sentencetexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=10, alpha=.1, l1_ratio=.5).fit(tfidfnmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "right hand away side guess gun turn degarmo next place thing behind better left front may quite told done even\n",
      "Topic #1:\n",
      "time long first much take next ago last lot come another enough took give going seemed thanks part every place\n",
      "Topic #2:\n",
      "marlowe mr name good yes voice named wade come please well call sorry look spencer oh much nice see sit\n",
      "Topic #3:\n",
      "asked softly voice quietly slowly ohls spencer suddenly looking come called patton drink mrs number french office degarmo dr carefully\n",
      "Topic #4:\n",
      "think might make much ever something really going better hell made maybe enough even guy reason find idea killed tough\n",
      "Topic #5:\n",
      "anything say well mean else something tell never might nobody knew hear things wrong really care done sort mrs find\n",
      "Topic #6:\n",
      "go see let come home wanted tell away even bed look far house people guy never take office way told\n",
      "Topic #7:\n",
      "door eyes came face way open opened hand still head room car gun look away turned stood something two shut\n",
      "Topic #8:\n",
      "nothing else happened except heard much stared tell moved face told us left either wait found ever even business everything\n",
      "Topic #9:\n",
      "want something talk tell money make see find ask really found even drink give much mrs police suppose maybe done\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, tfidf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### lda outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0,\n",
    "  u'0.018*smiled + 0.016*set + 0.015*hold + 0.014*woman + 0.012*silence + 0.012*case + 0.011*clean + 0.010*hot + 0.010*mine + 0.009*part + 0.009*cop + 0.008*times + 0.008*women + 0.008*carpet + 0.008*mother + 0.008*lunch + 0.008*fell + 0.007*lovely + 0.007*sister + 0.007*vague'),\n",
    " (1,\n",
    "  u\"0.185*. + 0.073*, + 0.068*'' + 0.065*`` + 0.023*n't + 0.020*? + 0.013*'s + 0.004*'m + 0.003*time + 0.003*go + 0.003*'re + 0.003*right + 0.003*way + 0.003*: + 0.003*think + 0.003*something + 0.003*'d + 0.003*see + 0.003*nothing + 0.002*voice\"),\n",
    " (2,\n",
    "  u'0.033*desk + 0.030*hand + 0.024*asked + 0.020*slowly + 0.015*glass + 0.014*across + 0.013*stood + 0.013*smile + 0.013*reached + 0.013*stared + 0.012*corner + 0.011*leaned + 0.010*face + 0.010*bag + 0.010*held + 0.008*mouth + 0.008*feet + 0.008*saw + 0.008*pushed + 0.008*tried'),\n",
    " (3,\n",
    "  u'0.037*door + 0.028*eyes + 0.017*sat + 0.016*french + 0.016*face + 0.015*open + 0.013*white + 0.013*light + 0.012*dark + 0.012*front + 0.012*behind + 0.012*hands + 0.011*night + 0.010*opened + 0.010*talk + 0.009*chair + 0.009*cigarette + 0.009*hair + 0.008*room + 0.007*side'),\n",
    " (4,\n",
    "  u'0.017*head + 0.016*city + 0.016*moved + 0.015*really + 0.013*street + 0.012*along + 0.012*hung + 0.011*side + 0.011*bay + 0.010*ask + 0.010*inside + 0.010*watched + 0.010*photo + 0.009*shook + 0.009*air + 0.009*dollars + 0.009*matter + 0.008*loose + 0.008*idea + 0.008*card')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(0,\n",
    "  u\"0.020*think + 0.019*something + 0.015*gun + 0.015*look + 0.015*marlowe + 0.015*'ll + 0.014*might + 0.013*take + 0.013*took + 0.013*told + 0.012*going + 0.011*gave + 0.010*mr. + 0.010*another + 0.009*away + 0.009*business + 0.009*somebody + 0.009*call + 0.008*sure + 0.008*far\"),\n",
    " (1,\n",
    "  u\"0.110*n't + 0.017*time + 0.015*'re + 0.012*see + 0.012*voice + 0.011*want + 0.011*anything + 0.011*asked + 0.011*let + 0.010*long + 0.009*much + 0.009*say + 0.009*tell + 0.009*come + 0.008*nice + 0.008*even + 0.008*kind + 0.008*guy + 0.008*make + 0.007*head\"),\n",
    " (2,\n",
    "  u'0.014*door + 0.013*eyes + 0.009*came + 0.009*still + 0.007*stood + 0.007*open + 0.006*looking + 0.006*mouth + 0.006*light + 0.006*house + 0.006*face + 0.006*white + 0.006*made + 0.005*two + 0.005*cigarette + 0.005*opened + 0.005*hands + 0.005*night + 0.005*police + 0.005*last'),\n",
    " (3,\n",
    "  u\"0.028*way + 0.025*nothing + 0.019*good + 0.016*'ve + 0.015*money + 0.015*lot + 0.015*thought + 0.014*steelgrave + 0.013*dead + 0.012*started + 0.011*thing + 0.011*talk + 0.010*always + 0.010*seemed + 0.010*heard + 0.010*work + 0.009*guess + 0.009*must + 0.008*quite + 0.008*found\"),\n",
    " (4,\n",
    "  u'0.017*right + 0.017*desk + 0.015*room + 0.014*hand + 0.012*turned + 0.010*across + 0.010*well + 0.010*sat + 0.010*french + 0.010*slowly + 0.010*side + 0.009*car + 0.009*knew + 0.009*behind + 0.009*chair + 0.009*left + 0.008*along + 0.007*leaned + 0.007*reached + 0.007*stopped')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(0,\n",
    "  u'0.013*really + 0.012*amigo + 0.010*night + 0.010*dr. + 0.009*please + 0.009*moment + 0.009*closed + 0.007*lagardie + 0.007*may + 0.007*fingers + 0.007*saw + 0.006*minute + 0.006*makes + 0.005*perhaps + 0.005*sit + 0.005*hurt + 0.005*mrs. + 0.005*stop + 0.005*apartment + 0.005*years'),\n",
    " (1,\n",
    "  u'0.027*nothing + 0.024*marlowe + 0.018*come + 0.018*well + 0.014*never + 0.013*business + 0.012*nodded + 0.011*mean + 0.011*thing + 0.011*talk + 0.011*mr. + 0.011*guess + 0.010*weld + 0.010*drink + 0.008*mavis + 0.007*day + 0.007*care + 0.007*rather + 0.006*believe + 0.006*picture'),\n",
    " (2,\n",
    "  u'0.018*good + 0.015*maybe + 0.014*give + 0.013*stared + 0.012*ever + 0.011*heard + 0.011*keep + 0.010*course + 0.008*sorry + 0.007*point + 0.007*laughed + 0.007*sort + 0.006*pretty + 0.006*wade + 0.005*suddenly + 0.005*shrugged + 0.005*cards + 0.005*cleveland + 0.005*safe + 0.005*touch'),\n",
    " (3,\n",
    "  u'0.029*asked + 0.016*yes + 0.015*steelgrave + 0.014*name + 0.012*call + 0.011*orrin + 0.010*answer + 0.009*ought + 0.008*quest + 0.008*hung + 0.008*city + 0.008*called + 0.007*shook + 0.007*suppose + 0.007*wanted + 0.007*doctor + 0.006*seen + 0.006*bay + 0.006*mind + 0.006*friend'),\n",
    " (4,\n",
    "  u\"0.051*n't + 0.011*time + 0.010*think + 0.010*'re + 0.010*eyes + 0.010*want + 0.010*way + 0.009*something + 0.008*let + 0.008*came + 0.008*tell + 0.008*room + 0.008*look + 0.008*long + 0.008*voice + 0.007*face + 0.007*still + 0.007*took + 0.007*head + 0.006*make\"),\n",
    " (5,\n",
    "  u\"0.016*see + 0.016*anything + 0.014*say + 0.014*'ll + 0.014*away + 0.013*much + 0.013*gun + 0.013*french + 0.013*turned + 0.013*told + 0.011*take + 0.011*money + 0.011*might + 0.010*house + 0.009*started + 0.009*car + 0.008*dead + 0.008*beifus + 0.008*far + 0.007*better\"),\n",
    " (6,\n",
    "  u'0.020*right + 0.017*door + 0.013*desk + 0.012*hand + 0.012*thought + 0.011*stood + 0.010*sat + 0.008*open + 0.008*chair + 0.008*mouth + 0.007*leaned + 0.007*phone + 0.007*reached + 0.007*killed + 0.007*softly + 0.007*cigarette + 0.007*smile + 0.007*yeah + 0.007*hands + 0.007*glass')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(0,\n",
    "  u'0.983*\"n\\'t\" + 0.060*\"anything\" + 0.048*\"think\" + 0.045*\"want\" + 0.037*\"say\" + 0.035*\"see\" + 0.031*\"even\" + 0.031*\"tell\" + 0.029*\"much\" + 0.029*\"time\" + 0.027*\"make\" + 0.025*\"look\" + 0.024*\"way\" + 0.019*\"well\" + 0.019*\"enough\" + 0.019*\"something\" + 0.018*\"come\" + 0.018*\"take\" + 0.017*\"let\" + 0.017*\"long\"'),\n",
    " (1,\n",
    "  u'0.606*\"door\" + 0.171*\"came\" + 0.162*\"eyes\" + 0.162*\"room\" + 0.144*\"open\" + 0.144*\"face\" + 0.138*\"hand\" + 0.135*\"opened\" + 0.130*\"time\" + 0.120*\"front\" + 0.112*\"desk\" + 0.110*\"car\" + 0.106*\"long\" + 0.105*\"two\" + 0.104*\"across\" + 0.102*\"away\" + 0.100*\"head\" + 0.097*\"right\" + 0.094*\"behind\" + 0.089*\"stood\"'),\n",
    " (2,\n",
    "  u'-0.654*\"door\" + 0.365*\"time\" + 0.202*\"eyes\" + 0.169*\"long\" + 0.166*\"face\" + 0.142*\"right\" + 0.115*\"way\" + 0.112*\"hand\" + 0.110*\"\\'re\" + -0.107*\"opened\" + 0.098*\"something\" + -0.097*\"open\" + 0.097*\"head\" + 0.091*\"think\" + 0.087*\"away\" + 0.084*\"\\'ll\" + -0.080*\"n\\'t\" + 0.078*\"see\" + 0.077*\"might\" + 0.075*\"took\"'),\n",
    " (3,\n",
    "  u'-0.728*\"time\" + 0.413*\"eyes\" + 0.233*\"face\" + -0.196*\"door\" + -0.188*\"long\" + 0.159*\"hand\" + -0.095*\"think\" + 0.093*\"head\" + -0.081*\"\\'re\" + 0.076*\"still\" + -0.073*\"\\'ll\" + 0.070*\"desk\" + 0.062*\"white\" + 0.060*\"turned\" + 0.060*\"right\" + 0.058*\"look\" + 0.055*\"black\" + 0.052*\"slowly\" + 0.051*\"dark\" + 0.051*\"sat\"'),\n",
    " (4,\n",
    "  u'0.570*\"eyes\" + 0.411*\"time\" + -0.262*\"\\'re\" + -0.248*\"right\" + 0.212*\"face\" + -0.194*\"think\" + -0.194*\"way\" + -0.140*\"\\'ll\" + 0.134*\"long\" + -0.116*\"car\" + -0.107*\"hand\" + -0.095*\"away\" + -0.095*\"marlowe\" + -0.090*\"might\" + -0.089*\"gun\" + -0.087*\"see\" + -0.073*\"mr.\" + -0.072*\"want\" + -0.071*\"two\" + -0.071*\"guy\"'),\n",
    " (5,\n",
    "  u'0.393*\"\\'re\" + 0.367*\"eyes\" + 0.346*\"think\" + -0.313*\"hand\" + -0.223*\"right\" + 0.168*\"something\" + 0.167*\"\\'ll\" + -0.153*\"gun\" + -0.151*\"time\" + -0.147*\"took\" + 0.139*\"marlowe\" + 0.134*\"see\" + -0.124*\"away\" + 0.120*\"door\" + -0.119*\"came\" + -0.119*\"desk\" + 0.111*\"way\" + 0.106*\"mr.\" + 0.104*\"might\" + -0.101*\"car\"'),\n",
    " (6,\n",
    "  u'-0.576*\"right\" + -0.349*\"hand\" + 0.330*\"way\" + -0.280*\"\\'re\" + 0.210*\"room\" + 0.189*\"car\" + 0.172*\"two\" + 0.170*\"came\" + -0.147*\"think\" + -0.146*\"gun\" + -0.146*\"eyes\" + -0.137*\"door\" + -0.109*\"time\" + 0.097*\"across\" + 0.086*\"see\" + 0.083*\"house\" + 0.076*\"long\" + 0.070*\"desk\" + -0.060*\"took\" + 0.054*\"sat\"'),\n",
    " (7,\n",
    "  u'-0.699*\"way\" + 0.338*\"face\" + -0.278*\"eyes\" + -0.255*\"right\" + 0.207*\"think\" + 0.202*\"came\" + 0.202*\"\\'re\" + -0.113*\"hand\" + -0.094*\"long\" + 0.084*\"two\" + -0.082*\"gun\" + 0.082*\"desk\" + 0.074*\"marlowe\" + 0.066*\"mr.\" + 0.065*\"away\" + -0.063*\"want\" + -0.061*\"\\'ll\" + -0.058*\"door\" + 0.055*\"much\" + -0.055*\"come\"'),\n",
    " (8,\n",
    "  u'0.644*\"see\" + -0.379*\"think\" + -0.300*\"way\" + 0.290*\"want\" + 0.238*\"\\'ll\" + -0.223*\"\\'re\" + 0.135*\"mr.\" + 0.128*\"something\" + 0.127*\"marlowe\" + 0.102*\"right\" + -0.101*\"room\" + 0.099*\"came\" + 0.088*\"let\" + 0.084*\"look\" + 0.082*\"voice\" + -0.082*\"long\" + -0.080*\"desk\" + -0.057*\"across\" + -0.047*\"sat\" + 0.040*\"tell\"'),\n",
    " (9,\n",
    "  u'0.786*\"face\" + 0.332*\"way\" + -0.320*\"eyes\" + -0.186*\"room\" + -0.167*\"two\" + -0.122*\"came\" + -0.121*\"car\" + -0.084*\"think\" + 0.084*\"door\" + -0.059*\"\\'re\" + -0.049*\"much\" + -0.048*\"house\" + -0.046*\"desk\" + 0.045*\"want\" + 0.044*\"see\" + -0.044*\"big\" + 0.039*\"let\" + -0.035*\"made\" + -0.035*\"front\" + -0.034*\"along\"')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic #0:\n",
    "right hand away side guess gun turn degarmo next place thing behind better left front may quite told done even\n",
    "\n",
    "Topic #1:\n",
    "time long first much take next ago last lot come another enough took give going seemed thanks part every place\n",
    "\n",
    "Topic #2:\n",
    "marlowe mr name good yes voice named wade come please well call sorry look spencer oh much nice see sit\n",
    "\n",
    "Topic #3:\n",
    "asked softly voice quietly slowly ohls spencer suddenly looking come called patton drink mrs number french office degarmo dr carefully\n",
    "\n",
    "Topic #4:\n",
    "think might make much ever something really going better hell made maybe enough even guy reason find idea killed tough\n",
    "\n",
    "Topic #5:\n",
    "anything say well mean else something tell never might nobody knew hear things wrong really care done sort mrs find\n",
    "\n",
    "Topic #6:\n",
    "go see let come home wanted tell away even bed look far house people guy never take office way told\n",
    "\n",
    "Topic #7:\n",
    "door eyes came face way open opened hand still head room car gun look away turned stood something two shut\n",
    "\n",
    "Topic #8:\n",
    "nothing else happened except heard much stared tell moved face told us left either wait found ever even business everything\n",
    "\n",
    "Topic #9:\n",
    "want something talk tell money make see find ask really found even drink give much mrs police suppose maybe done\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
