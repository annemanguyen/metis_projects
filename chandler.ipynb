{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop.append('said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "path = '/home/amn34/metis/stuff/noirs/chandler'\n",
    "for books in glob.glob(os.path.join(path, '*.txt')):\n",
    "    doc = open(books).read()\n",
    "    doc = doc.decode('utf-8')\n",
    "    doc = doc.lower()\n",
    "    docwords = tokenizer.tokenize(doc)\n",
    "    stopped = [w for w in docwords if not w in stop]\n",
    "    p_stem = PorterStemmer()\n",
    "    stemmed_words = [p_stemmer.stem(i) for i in stopped]\n",
    "    texts.append(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book: [u'hous', u'dresden', u'avenu', u'oak', u'noll', u'section', u'pasadena', u'big', u'solid', u'cool', u'look', u'hous', u'burgundi', u'brick', u'wall', u'terra', u'cotta', u'tile', u'roof', u'white', u'stone', u'trim', u'front', u'window', u'lead', u'downstair', u'upstair', u'window', u'cottag', u'type', u'lot', u'rococo', u'imit', u'stonework', u'trim', u'around', u'front', u'wall', u'attend', u'flower', u'bush', u'half', u'acr', u'fine', u'green', u'lawn', u'drift', u'gentl', u'slope', u'street'] \n",
      "\n",
      "book: [u'one', u'mix', u'block', u'central', u'avenu', u'block', u'yet', u'negro', u'come', u'three', u'chair', u'barber', u'shop', u'agenc', u'thought', u'relief', u'barber', u'name', u'dimitrio', u'aleidi', u'might', u'work', u'small', u'matter', u'wife', u'will', u'spend', u'littl', u'money', u'come', u'home', u'never', u'found', u'mr', u'aleidi', u'never', u'paid', u'money', u'either', u'warm', u'day', u'almost', u'end', u'march', u'stood', u'outsid', u'barber', u'shop', u'look', u'jut'] \n",
      "\n",
      "book: [u'pebbl', u'glass', u'door', u'panel', u'letter', u'flake', u'black', u'paint', u'philip', u'marlow', u'investig', u'reason', u'shabbi', u'door', u'end', u'reason', u'shabbi', u'corridor', u'sort', u'build', u'new', u'year', u'tile', u'bathroom', u'becam', u'basi', u'civil', u'door', u'lock', u'next', u'anoth', u'door', u'legend', u'lock', u'come', u'nobodi', u'big', u'bluebottl', u'fli', u'manhattan', u'kansa', u'one', u'clear', u'bright', u'summer', u'morn', u'get', u'earli', u'spring', u'california'] \n",
      "\n",
      "book: [u'voic', u'telephon', u'seem', u'sharp', u'peremptori', u'hear', u'well', u'partli', u'half', u'awak', u'partli', u'hold', u'receiv', u'upsid', u'fumbl', u'around', u'grunt', u'hear', u'clyde', u'umney', u'lawyer', u'clyde', u'umney', u'lawyer', u'thought', u'sever', u'marlow', u'yeah', u'guess', u'look', u'wrist', u'watch', u'6', u'30', u'best', u'hour', u'get', u'fresh', u'young', u'man', u'sorri', u'mr', u'umney', u'young', u'man', u'old', u'tire', u'full', u'coffe', u'sir'] \n",
      "\n",
      "book: [u'first', u'time', u'laid', u'eye', u'terri', u'lennox', u'drunk', u'roll', u'royc', u'silver', u'wraith', u'outsid', u'terrac', u'dancer', u'park', u'lot', u'attend', u'brought', u'car', u'still', u'hold', u'door', u'open', u'terri', u'lennox', u'left', u'foot', u'still', u'dangl', u'outsid', u'forgotten', u'one', u'young', u'look', u'face', u'hair', u'bone', u'white', u'could', u'tell', u'eye', u'plaster', u'hairlin', u'otherwis', u'look', u'like', u'nice', u'young', u'guy', u'dinner'] \n",
      "\n",
      "book: [u'treloar', u'build', u'oliv', u'street', u'near', u'sixth', u'west', u'side', u'sidewalk', u'front', u'built', u'black', u'white', u'rubber', u'block', u'take', u'give', u'govern', u'hatless', u'pale', u'man', u'face', u'like', u'build', u'superintend', u'watch', u'work', u'look', u'break', u'heart', u'went', u'past', u'arcad', u'specialti', u'shop', u'vast', u'black', u'gold', u'lobbi', u'gillerlain', u'compani', u'seventh', u'floor', u'front', u'behind', u'swing', u'doubl', u'plate', u'glass', u'door'] \n",
      "\n",
      "book: [u'eleven', u'clock', u'morn', u'mid', u'octob', u'sun', u'shine', u'look', u'hard', u'wet', u'rain', u'clear', u'foothil', u'wear', u'powder', u'blue', u'suit', u'dark', u'blue', u'shirt', u'tie', u'display', u'handkerchief', u'black', u'brogu', u'black', u'wool', u'sock', u'dark', u'blue', u'clock', u'neat', u'clean', u'shave', u'sober', u'care', u'knew', u'everyth', u'well', u'dress', u'privat', u'detect', u'ought', u'call', u'four', u'million', u'dollar', u'main', u'hallway', u'sternwood'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in texts: print 'book:', i[0:50], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sleep = open('/home/amn34/metis/stuff/noirs/rc_bigsleep.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sleep = sleep.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sleepsent = sent_tokenize(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#raw = sleep.lower()\n",
    "#sleepwords = tokenizer.tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stopped = [w for w in sleepwords if not w in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stemmed_words = [p_stemmer.stem(i) for i in stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look\n",
      "like\n",
      "back\n",
      "know\n",
      "went\n",
      "door\n",
      "would\n",
      "mr\n",
      "get\n",
      "littl\n",
      "hand\n",
      "one\n",
      "man\n",
      "go\n",
      "eye\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "like\n",
      "back\n",
      "one\n",
      "get\n",
      "man\n",
      "went\n",
      "littl\n",
      "got\n",
      "door\n",
      "go\n",
      "eye\n",
      "hand\n",
      "know\n",
      "would\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "like\n",
      "back\n",
      "littl\n",
      "know\n",
      "went\n",
      "one\n",
      "get\n",
      "door\n",
      "would\n",
      "hand\n",
      "got\n",
      "man\n",
      "go\n",
      "eye\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "back\n",
      "went\n",
      "know\n",
      "get\n",
      "could\n",
      "one\n",
      "got\n",
      "would\n",
      "like\n",
      "man\n",
      "mitchel\n",
      "mr\n",
      "car\n",
      "door\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "get\n",
      "got\n",
      "like\n",
      "know\n",
      "one\n",
      "back\n",
      "would\n",
      "time\n",
      "mr\n",
      "went\n",
      "want\n",
      "could\n",
      "man\n",
      "wade\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "like\n",
      "back\n",
      "know\n",
      "went\n",
      "would\n",
      "littl\n",
      "one\n",
      "got\n",
      "get\n",
      "degarmo\n",
      "go\n",
      "kingsley\n",
      "hand\n",
      "door\n",
      "\n",
      "\n",
      "\n",
      "look\n",
      "like\n",
      "back\n",
      "went\n",
      "door\n",
      "eye\n",
      "know\n",
      "got\n",
      "littl\n",
      "man\n",
      "get\n",
      "would\n",
      "one\n",
      "car\n",
      "hand\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus2 = []\n",
    "\n",
    "for i in corpus:\n",
    "    s = sorted(i, key=lambda x: x[1], reverse=True)\n",
    "    corpus2.append(s[20:])\n",
    "    for j in s[0:15]:\n",
    "        print dictionary.get(j[0])\n",
    "    print '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, alpha = 'auto', id2word = dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.011*look + 0.009*like + 0.008*back + 0.007*know + 0.007*went'), (1, u'0.012*look + 0.009*like + 0.008*back + 0.007*get + 0.007*one'), (2, u'0.010*look + 0.009*like + 0.009*back + 0.006*went + 0.006*door'), (3, u'0.010*look + 0.008*get + 0.008*back + 0.007*got + 0.007*like'), (4, u'0.013*look + 0.008*like + 0.008*back + 0.007*know + 0.007*went')]\n"
     ]
    }
   ],
   "source": [
    "print ldamodel.print_topics(num_topics=5, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel2 = gensim.models.ldamodel.LdaModel(corpus2, num_topics=5, alpha = 'auto', id2word = dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
